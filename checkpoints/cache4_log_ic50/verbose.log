Command line
python /Users/judewells/Documents/dataScienceProgramming/cache4/models/train_chemprop_regression.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'ligand_files/chemprop_train.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['r2', 'mae'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse', 'r2', 'mae'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'chemprop_regression_logIC50',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': ['log_ic50'],
 'target_weights': None,
 'task_names': ['log_ic50'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Setting molecule featurization parameters to default.
Loading data
Command line
python /Users/judewells/Documents/dataScienceProgramming/cache4/models/train_chemprop_regression.py
Args
{'activation': 'ReLU',
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'ligand_files/chemprop_regression_no_split.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['r2', 'mae'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse', 'r2', 'mae'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 5,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'chemprop_regression_logIC50',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'scaffold_balanced',
 'target_columns': ['log_ic50'],
 'target_weights': None,
 'task_names': ['log_ic50'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total scaffolds = 368 | train scaffolds = 267 | val scaffolds = 54 | test scaffolds = 47
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 37 | target average = 2.967741


Scaffold 1
Task 0: count = 37 | target average = 2.386357


Scaffold 2
Task 0: count = 29 | target average = 0.301030


Scaffold 3
Task 0: count = 22 | target average = 0.301030


Scaffold 4
Task 0: count = 22 | target average = 0.415222


Scaffold 5
Task 0: count = 19 | target average = 2.857016


Scaffold 6
Task 0: count = 16 | target average = 3.646747


Scaffold 7
Task 0: count = 15 | target average = 3.333860


Scaffold 8
Task 0: count = 15 | target average = 3.662865


Scaffold 9
Task 0: count = 15 | target average = 3.556767


Total size = 895 | train size = 716 | val size = 89 | test size = 90
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 8.6874e-01, PNorm = 34.0171, GNorm = 1.5964, lr_0 = 4.5357e-04
Validation rmse = 1.346519
Validation r2 = 0.136600
Validation mae = 1.164024
Epoch 1
Loss = 5.3671e-01, PNorm = 34.0421, GNorm = 4.9607, lr_0 = 8.0714e-04
Validation rmse = 1.522403
Validation r2 = -0.103687
Validation mae = 1.257949
Epoch 2
Loss = 3.8926e-01, PNorm = 34.0774, GNorm = 1.2939, lr_0 = 9.7106e-04
Loss = 4.2573e-01, PNorm = 34.1152, GNorm = 2.3861, lr_0 = 9.1566e-04
Validation rmse = 1.341553
Validation r2 = 0.142957
Validation mae = 1.060836
Epoch 3
Loss = 4.0500e-01, PNorm = 34.1524, GNorm = 2.8413, lr_0 = 8.5837e-04
Validation rmse = 1.255756
Validation r2 = 0.249073
Validation mae = 0.953785
Epoch 4
Loss = 4.7854e-01, PNorm = 34.1871, GNorm = 7.2532, lr_0 = 8.0940e-04
Loss = 3.9357e-01, PNorm = 34.2206, GNorm = 2.9923, lr_0 = 7.6323e-04
Validation rmse = 1.290407
Validation r2 = 0.207061
Validation mae = 1.005665
Epoch 5
Loss = 3.2506e-01, PNorm = 34.2614, GNorm = 1.6303, lr_0 = 7.1547e-04
Validation rmse = 1.179901
Validation r2 = 0.337054
Validation mae = 0.870265
Epoch 6
Loss = 2.8786e-01, PNorm = 34.3007, GNorm = 1.7755, lr_0 = 6.7070e-04
Loss = 2.9936e-01, PNorm = 34.3283, GNorm = 1.2431, lr_0 = 6.3244e-04
Validation rmse = 1.149690
Validation r2 = 0.370569
Validation mae = 0.815809
Epoch 7
Loss = 2.7989e-01, PNorm = 34.3467, GNorm = 1.7412, lr_0 = 5.9636e-04
Validation rmse = 1.254612
Validation r2 = 0.250442
Validation mae = 0.958141
Epoch 8
Loss = 3.2582e-01, PNorm = 34.3646, GNorm = 0.5614, lr_0 = 5.5905e-04
Validation rmse = 1.153456
Validation r2 = 0.366438
Validation mae = 0.793389
Epoch 9
Loss = 3.7415e-01, PNorm = 34.3877, GNorm = 4.0380, lr_0 = 5.2407e-04
Loss = 2.7259e-01, PNorm = 34.4049, GNorm = 0.5273, lr_0 = 4.9417e-04
Validation rmse = 1.187064
Validation r2 = 0.328981
Validation mae = 0.836034
Epoch 10
Loss = 2.5150e-01, PNorm = 34.4208, GNorm = 1.2992, lr_0 = 4.6598e-04
Validation rmse = 1.158874
Validation r2 = 0.360473
Validation mae = 0.828345
Epoch 11
Loss = 2.7969e-01, PNorm = 34.4428, GNorm = 0.8254, lr_0 = 4.3682e-04
Loss = 2.5205e-01, PNorm = 34.4559, GNorm = 0.7513, lr_0 = 4.1190e-04
Validation rmse = 1.158696
Validation r2 = 0.360669
Validation mae = 0.857571
Epoch 12
Loss = 2.9342e-01, PNorm = 34.4701, GNorm = 0.6554, lr_0 = 3.8613e-04
Validation rmse = 1.165700
Validation r2 = 0.352916
Validation mae = 0.819645
Epoch 13
Loss = 2.6362e-01, PNorm = 34.4824, GNorm = 2.4184, lr_0 = 3.6410e-04
Loss = 2.7683e-01, PNorm = 34.4937, GNorm = 3.6177, lr_0 = 3.4333e-04
Loss = 7.0833e-02, PNorm = 34.4948, GNorm = 1.6124, lr_0 = 3.4132e-04
Validation rmse = 1.156213
Validation r2 = 0.363406
Validation mae = 0.828600
Epoch 14
Loss = 2.7167e-01, PNorm = 34.5074, GNorm = 1.9942, lr_0 = 3.2185e-04
Validation rmse = 1.172196
Validation r2 = 0.345685
Validation mae = 0.834374
Epoch 15
Loss = 2.3964e-01, PNorm = 34.5229, GNorm = 1.6492, lr_0 = 3.0171e-04
Validation rmse = 1.127043
Validation r2 = 0.395122
Validation mae = 0.791799
Epoch 16
Loss = 2.8084e-01, PNorm = 34.5343, GNorm = 2.5287, lr_0 = 2.8450e-04
Loss = 2.4319e-01, PNorm = 34.5466, GNorm = 0.6685, lr_0 = 2.6827e-04
Validation rmse = 1.183467
Validation r2 = 0.333041
Validation mae = 0.864484
Epoch 17
Loss = 2.1267e-01, PNorm = 34.5595, GNorm = 0.6712, lr_0 = 2.5148e-04
Validation rmse = 1.168025
Validation r2 = 0.350333
Validation mae = 0.830059
Epoch 18
Loss = 2.7174e-01, PNorm = 34.5706, GNorm = 1.6836, lr_0 = 2.3575e-04
Loss = 2.5003e-01, PNorm = 34.5805, GNorm = 4.9431, lr_0 = 2.2230e-04
Validation rmse = 1.145945
Validation r2 = 0.374663
Validation mae = 0.798053
Epoch 19
Loss = 2.5389e-01, PNorm = 34.5906, GNorm = 1.7185, lr_0 = 2.0962e-04
Validation rmse = 1.141253
Validation r2 = 0.379773
Validation mae = 0.793499
Epoch 20
Loss = 1.9427e-01, PNorm = 34.6014, GNorm = 1.4724, lr_0 = 1.9650e-04
Loss = 2.5882e-01, PNorm = 34.6114, GNorm = 2.7935, lr_0 = 1.8529e-04
Loss = 1.4678e-01, PNorm = 34.6125, GNorm = 1.5966, lr_0 = 1.8421e-04
Validation rmse = 1.137099
Validation r2 = 0.384280
Validation mae = 0.775014
Epoch 21
Loss = 2.3507e-01, PNorm = 34.6215, GNorm = 2.7758, lr_0 = 1.7370e-04
Validation rmse = 1.131425
Validation r2 = 0.390410
Validation mae = 0.784914
Epoch 22
Loss = 2.2120e-01, PNorm = 34.6279, GNorm = 1.3648, lr_0 = 1.6379e-04
Validation rmse = 1.145412
Validation r2 = 0.375244
Validation mae = 0.776979
Epoch 23
Loss = 2.1743e-01, PNorm = 34.6378, GNorm = 2.6164, lr_0 = 1.5354e-04
Loss = 2.5049e-01, PNorm = 34.6461, GNorm = 1.3501, lr_0 = 1.4478e-04
Validation rmse = 1.151830
Validation r2 = 0.368223
Validation mae = 0.793140
Epoch 24
Loss = 2.1669e-01, PNorm = 34.6544, GNorm = 0.4607, lr_0 = 1.3572e-04
Validation rmse = 1.135950
Validation r2 = 0.385524
Validation mae = 0.783139
Epoch 25
Loss = 2.7695e-01, PNorm = 34.6609, GNorm = 1.3382, lr_0 = 1.2798e-04
Loss = 2.3726e-01, PNorm = 34.6675, GNorm = 2.4296, lr_0 = 1.2068e-04
Validation rmse = 1.147601
Validation r2 = 0.372854
Validation mae = 0.791102
Epoch 26
Loss = 2.2045e-01, PNorm = 34.6736, GNorm = 1.2134, lr_0 = 1.1313e-04
Validation rmse = 1.133319
Validation r2 = 0.388367
Validation mae = 0.779549
Epoch 27
Loss = 2.8723e-01, PNorm = 34.6810, GNorm = 0.9139, lr_0 = 1.0605e-04
Loss = 2.1231e-01, PNorm = 34.6871, GNorm = 1.6116, lr_0 = 1.0000e-04
Loss = 3.3221e-01, PNorm = 34.6879, GNorm = 3.6296, lr_0 = 1.0000e-04
Validation rmse = 1.146821
Validation r2 = 0.373707
Validation mae = 0.785651
Epoch 28
Loss = 2.3480e-01, PNorm = 34.6936, GNorm = 0.8671, lr_0 = 1.0000e-04
Validation rmse = 1.193398
Validation r2 = 0.321801
Validation mae = 0.858450
Epoch 29
Loss = 2.5052e-01, PNorm = 34.6997, GNorm = 0.9561, lr_0 = 1.0000e-04
Validation rmse = 1.170650
Validation r2 = 0.347409
Validation mae = 0.818579
Model 0 best validation rmse = 1.127043 on epoch 15
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.824925
Model 0 test r2 = 0.660210
Model 0 test mae = 0.599342
Ensemble test rmse = 0.824925
Ensemble test r2 = 0.660210
Ensemble test mae = 0.599342
Fold 1
Splitting data with seed 1
Total scaffolds = 368 | train scaffolds = 273 | val scaffolds = 46 | test scaffolds = 49
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 37 | target average = 2.967741


Scaffold 1
Task 0: count = 37 | target average = 2.386357


Scaffold 2
Task 0: count = 29 | target average = 0.301030


Scaffold 3
Task 0: count = 22 | target average = 0.415222


Scaffold 4
Task 0: count = 22 | target average = 0.301030


Scaffold 5
Task 0: count = 19 | target average = 2.857016


Scaffold 6
Task 0: count = 16 | target average = 3.646747


Scaffold 7
Task 0: count = 15 | target average = 2.272125


Scaffold 8
Task 0: count = 15 | target average = 3.556767


Scaffold 9
Task 0: count = 15 | target average = 3.333860


Total size = 895 | train size = 716 | val size = 89 | test size = 90
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 9.6649e-01, PNorm = 34.0149, GNorm = 11.8696, lr_0 = 4.5357e-04
Validation rmse = 1.087252
Validation r2 = 0.457419
Validation mae = 0.894577
Epoch 1
Loss = 6.1113e-01, PNorm = 34.0429, GNorm = 0.3917, lr_0 = 8.0714e-04
Validation rmse = 1.020124
Validation r2 = 0.522350
Validation mae = 0.774995
Epoch 2
Loss = 5.0625e-01, PNorm = 34.0764, GNorm = 1.3333, lr_0 = 9.7106e-04
Loss = 5.5304e-01, PNorm = 34.1165, GNorm = 0.4310, lr_0 = 9.1566e-04
Validation rmse = 1.105348
Validation r2 = 0.439207
Validation mae = 0.814691
Epoch 3
Loss = 4.5193e-01, PNorm = 34.1567, GNorm = 0.7929, lr_0 = 8.5837e-04
Validation rmse = 0.960201
Validation r2 = 0.576817
Validation mae = 0.655172
Epoch 4
Loss = 4.0070e-01, PNorm = 34.1952, GNorm = 0.9591, lr_0 = 8.0940e-04
Loss = 4.1389e-01, PNorm = 34.2284, GNorm = 4.4236, lr_0 = 7.6323e-04
Validation rmse = 0.911375
Validation r2 = 0.618760
Validation mae = 0.593465
Epoch 5
Loss = 3.9045e-01, PNorm = 34.2649, GNorm = 4.5548, lr_0 = 7.1547e-04
Validation rmse = 0.912228
Validation r2 = 0.618046
Validation mae = 0.565641
Epoch 6
Loss = 3.3637e-01, PNorm = 34.2901, GNorm = 0.4731, lr_0 = 6.7070e-04
Loss = 3.5537e-01, PNorm = 34.3117, GNorm = 4.5199, lr_0 = 6.3244e-04
Validation rmse = 0.852638
Validation r2 = 0.666317
Validation mae = 0.560544
Epoch 7
Loss = 3.4835e-01, PNorm = 34.3330, GNorm = 5.6118, lr_0 = 5.9636e-04
Validation rmse = 0.853070
Validation r2 = 0.665979
Validation mae = 0.539838
Epoch 8
Loss = 3.6833e-01, PNorm = 34.3478, GNorm = 1.3074, lr_0 = 5.5905e-04
Validation rmse = 0.869292
Validation r2 = 0.653155
Validation mae = 0.544112
Epoch 9
Loss = 2.8132e-01, PNorm = 34.3702, GNorm = 1.4304, lr_0 = 5.2407e-04
Loss = 3.4346e-01, PNorm = 34.3826, GNorm = 7.0446, lr_0 = 4.9417e-04
Validation rmse = 0.963351
Validation r2 = 0.574035
Validation mae = 0.680749
Epoch 10
Loss = 3.4120e-01, PNorm = 34.3945, GNorm = 3.1377, lr_0 = 4.6598e-04
Validation rmse = 0.858910
Validation r2 = 0.661390
Validation mae = 0.541788
Epoch 11
Loss = 3.0252e-01, PNorm = 34.4125, GNorm = 1.9471, lr_0 = 4.3682e-04
Loss = 3.1337e-01, PNorm = 34.4276, GNorm = 0.7018, lr_0 = 4.1190e-04
Validation rmse = 0.877098
Validation r2 = 0.646898
Validation mae = 0.552797
Epoch 12
Loss = 3.2919e-01, PNorm = 34.4415, GNorm = 0.7963, lr_0 = 3.8613e-04
Validation rmse = 0.855122
Validation r2 = 0.664370
Validation mae = 0.532617
Epoch 13
Loss = 4.1603e-01, PNorm = 34.4515, GNorm = 1.2326, lr_0 = 3.6410e-04
Loss = 2.6372e-01, PNorm = 34.4659, GNorm = 1.0177, lr_0 = 3.4333e-04
Loss = 4.7940e-01, PNorm = 34.4674, GNorm = 5.6197, lr_0 = 3.4132e-04
Validation rmse = 0.865316
Validation r2 = 0.656321
Validation mae = 0.535040
Epoch 14
Loss = 2.8396e-01, PNorm = 34.4781, GNorm = 0.6463, lr_0 = 3.2185e-04
Validation rmse = 0.819399
Validation r2 = 0.691827
Validation mae = 0.573155
Epoch 15
Loss = 3.2428e-01, PNorm = 34.4880, GNorm = 0.8000, lr_0 = 3.0171e-04
Validation rmse = 0.836467
Validation r2 = 0.678854
Validation mae = 0.545102
Epoch 16
Loss = 3.3198e-01, PNorm = 34.5003, GNorm = 2.2303, lr_0 = 2.8450e-04
Loss = 3.1463e-01, PNorm = 34.5120, GNorm = 1.2408, lr_0 = 2.6827e-04
Validation rmse = 0.864675
Validation r2 = 0.656830
Validation mae = 0.542183
Epoch 17
Loss = 2.7410e-01, PNorm = 34.5240, GNorm = 4.6266, lr_0 = 2.5148e-04
Validation rmse = 0.828013
Validation r2 = 0.685313
Validation mae = 0.528714
Epoch 18
Loss = 2.5580e-01, PNorm = 34.5334, GNorm = 1.9244, lr_0 = 2.3575e-04
Loss = 3.0545e-01, PNorm = 34.5439, GNorm = 0.9912, lr_0 = 2.2230e-04
Validation rmse = 0.866588
Validation r2 = 0.655310
Validation mae = 0.555102
Epoch 19
Loss = 3.3133e-01, PNorm = 34.5542, GNorm = 4.7328, lr_0 = 2.0962e-04
Validation rmse = 0.895556
Validation r2 = 0.631880
Validation mae = 0.567243
Epoch 20
Loss = 3.4402e-01, PNorm = 34.5653, GNorm = 1.7085, lr_0 = 1.9650e-04
Loss = 2.6826e-01, PNorm = 34.5737, GNorm = 0.8601, lr_0 = 1.8529e-04
Loss = 5.1907e-01, PNorm = 34.5744, GNorm = 3.9038, lr_0 = 1.8421e-04
Validation rmse = 0.820929
Validation r2 = 0.690675
Validation mae = 0.541770
Epoch 21
Loss = 2.9076e-01, PNorm = 34.5824, GNorm = 1.8485, lr_0 = 1.7370e-04
Validation rmse = 0.826501
Validation r2 = 0.686462
Validation mae = 0.524657
Epoch 22
Loss = 2.5476e-01, PNorm = 34.5904, GNorm = 2.3033, lr_0 = 1.6379e-04
Validation rmse = 0.827725
Validation r2 = 0.685532
Validation mae = 0.525986
Epoch 23
Loss = 3.5067e-01, PNorm = 34.5980, GNorm = 1.0769, lr_0 = 1.5354e-04
Loss = 2.5238e-01, PNorm = 34.6061, GNorm = 0.5734, lr_0 = 1.4478e-04
Validation rmse = 0.830632
Validation r2 = 0.683319
Validation mae = 0.521582
Epoch 24
Loss = 3.1917e-01, PNorm = 34.6145, GNorm = 1.0457, lr_0 = 1.3572e-04
Validation rmse = 0.825890
Validation r2 = 0.686925
Validation mae = 0.523808
Epoch 25
Loss = 2.6258e-01, PNorm = 34.6210, GNorm = 1.0581, lr_0 = 1.2798e-04
Loss = 3.4083e-01, PNorm = 34.6274, GNorm = 4.9070, lr_0 = 1.2068e-04
Validation rmse = 0.809927
Validation r2 = 0.698910
Validation mae = 0.542851
Epoch 26
Loss = 2.9448e-01, PNorm = 34.6335, GNorm = 2.1889, lr_0 = 1.1313e-04
Validation rmse = 0.820086
Validation r2 = 0.691310
Validation mae = 0.520624
Epoch 27
Loss = 2.7863e-01, PNorm = 34.6397, GNorm = 2.4979, lr_0 = 1.0605e-04
Loss = 2.9327e-01, PNorm = 34.6449, GNorm = 0.8452, lr_0 = 1.0000e-04
Loss = 2.6566e-01, PNorm = 34.6453, GNorm = 0.6695, lr_0 = 1.0000e-04
Validation rmse = 0.809061
Validation r2 = 0.699554
Validation mae = 0.533714
Epoch 28
Loss = 2.7527e-01, PNorm = 34.6511, GNorm = 2.7677, lr_0 = 1.0000e-04
Validation rmse = 0.814151
Validation r2 = 0.695762
Validation mae = 0.526001
Epoch 29
Loss = 2.6747e-01, PNorm = 34.6552, GNorm = 2.8841, lr_0 = 1.0000e-04
Validation rmse = 0.857137
Validation r2 = 0.662787
Validation mae = 0.546579
Model 0 best validation rmse = 0.809061 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.724905
Model 0 test r2 = 0.735845
Model 0 test mae = 0.552496
Ensemble test rmse = 0.724905
Ensemble test r2 = 0.735845
Ensemble test mae = 0.552496
Fold 2
Splitting data with seed 2
Total scaffolds = 368 | train scaffolds = 318 | val scaffolds = 24 | test scaffolds = 26
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 37 | target average = 2.967741


Scaffold 1
Task 0: count = 37 | target average = 2.386357


Scaffold 2
Task 0: count = 29 | target average = 0.301030


Scaffold 3
Task 0: count = 22 | target average = 0.415222


Scaffold 4
Task 0: count = 22 | target average = 0.301030


Scaffold 5
Task 0: count = 19 | target average = 2.857016


Scaffold 6
Task 0: count = 16 | target average = 3.646747


Scaffold 7
Task 0: count = 15 | target average = 3.333860


Scaffold 8
Task 0: count = 15 | target average = 3.556767


Scaffold 9
Task 0: count = 15 | target average = 3.662865


Total size = 895 | train size = 716 | val size = 89 | test size = 90
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 8.7149e-01, PNorm = 34.0177, GNorm = 3.5154, lr_0 = 4.5357e-04
Validation rmse = 1.276612
Validation r2 = -0.099636
Validation mae = 1.121551
Epoch 1
Loss = 6.5096e-01, PNorm = 34.0426, GNorm = 2.3958, lr_0 = 8.0714e-04
Validation rmse = 0.926486
Validation r2 = 0.420826
Validation mae = 0.689981
Epoch 2
Loss = 4.3951e-01, PNorm = 34.0787, GNorm = 2.2104, lr_0 = 9.7106e-04
Loss = 4.2949e-01, PNorm = 34.1254, GNorm = 4.2905, lr_0 = 9.1566e-04
Validation rmse = 1.004472
Validation r2 = 0.319220
Validation mae = 0.727252
Epoch 3
Loss = 4.6267e-01, PNorm = 34.1679, GNorm = 2.2710, lr_0 = 8.5837e-04
Validation rmse = 0.909609
Validation r2 = 0.441734
Validation mae = 0.679053
Epoch 4
Loss = 3.7858e-01, PNorm = 34.2038, GNorm = 1.7001, lr_0 = 8.0940e-04
Loss = 4.3412e-01, PNorm = 34.2409, GNorm = 3.3645, lr_0 = 7.6323e-04
Validation rmse = 1.020190
Validation r2 = 0.297747
Validation mae = 0.734906
Epoch 5
Loss = 3.8794e-01, PNorm = 34.2836, GNorm = 1.4148, lr_0 = 7.1547e-04
Validation rmse = 0.903451
Validation r2 = 0.449268
Validation mae = 0.686686
Epoch 6
Loss = 4.1124e-01, PNorm = 34.3192, GNorm = 1.8954, lr_0 = 6.7070e-04
Loss = 3.2878e-01, PNorm = 34.3493, GNorm = 1.5150, lr_0 = 6.3244e-04
Validation rmse = 0.938139
Validation r2 = 0.406165
Validation mae = 0.677380
Epoch 7
Loss = 3.3702e-01, PNorm = 34.3736, GNorm = 1.0803, lr_0 = 5.9636e-04
Validation rmse = 0.916498
Validation r2 = 0.433246
Validation mae = 0.645132
Epoch 8
Loss = 3.0720e-01, PNorm = 34.4001, GNorm = 1.1276, lr_0 = 5.5905e-04
Validation rmse = 0.868126
Validation r2 = 0.491492
Validation mae = 0.633037
Epoch 9
Loss = 3.9851e-01, PNorm = 34.4166, GNorm = 3.5670, lr_0 = 5.2407e-04
Loss = 3.0379e-01, PNorm = 34.4343, GNorm = 0.3898, lr_0 = 4.9417e-04
Validation rmse = 0.895907
Validation r2 = 0.458426
Validation mae = 0.626745
Epoch 10
Loss = 3.2367e-01, PNorm = 34.4497, GNorm = 2.1112, lr_0 = 4.6598e-04
Validation rmse = 0.866185
Validation r2 = 0.493764
Validation mae = 0.606115
Epoch 11
Loss = 2.3394e-01, PNorm = 34.4670, GNorm = 1.5482, lr_0 = 4.3682e-04
Loss = 2.9572e-01, PNorm = 34.4794, GNorm = 0.4393, lr_0 = 4.1190e-04
Validation rmse = 0.871956
Validation r2 = 0.486996
Validation mae = 0.617458
Epoch 12
Loss = 2.9407e-01, PNorm = 34.4947, GNorm = 0.3183, lr_0 = 3.8613e-04
Validation rmse = 0.892425
Validation r2 = 0.462628
Validation mae = 0.620488
Epoch 13
Loss = 2.6058e-01, PNorm = 34.5104, GNorm = 1.4234, lr_0 = 3.6410e-04
Loss = 2.9362e-01, PNorm = 34.5226, GNorm = 1.7286, lr_0 = 3.4333e-04
Loss = 1.5914e-01, PNorm = 34.5244, GNorm = 1.7797, lr_0 = 3.4132e-04
Validation rmse = 0.892587
Validation r2 = 0.462433
Validation mae = 0.639057
Epoch 14
Loss = 2.8234e-01, PNorm = 34.5385, GNorm = 1.6949, lr_0 = 3.2185e-04
Validation rmse = 0.903745
Validation r2 = 0.448909
Validation mae = 0.643442
Epoch 15
Loss = 2.4228e-01, PNorm = 34.5500, GNorm = 1.2058, lr_0 = 3.0171e-04
Validation rmse = 0.887877
Validation r2 = 0.468092
Validation mae = 0.626897
Epoch 16
Loss = 3.6388e-01, PNorm = 34.5656, GNorm = 0.7625, lr_0 = 2.8450e-04
Loss = 2.6814e-01, PNorm = 34.5781, GNorm = 0.5682, lr_0 = 2.6827e-04
Validation rmse = 0.862030
Validation r2 = 0.498609
Validation mae = 0.606094
Epoch 17
Loss = 2.7463e-01, PNorm = 34.5937, GNorm = 1.4604, lr_0 = 2.5148e-04
Validation rmse = 0.846788
Validation r2 = 0.516184
Validation mae = 0.604058
Epoch 18
Loss = 2.3232e-01, PNorm = 34.6053, GNorm = 1.5498, lr_0 = 2.3575e-04
Loss = 2.6578e-01, PNorm = 34.6179, GNorm = 0.5180, lr_0 = 2.2230e-04
Validation rmse = 0.887481
Validation r2 = 0.468566
Validation mae = 0.625462
Epoch 19
Loss = 2.3151e-01, PNorm = 34.6294, GNorm = 2.3638, lr_0 = 2.0962e-04
Validation rmse = 0.892700
Validation r2 = 0.462297
Validation mae = 0.637029
Epoch 20
Loss = 3.0890e-01, PNorm = 34.6419, GNorm = 4.9722, lr_0 = 1.9650e-04
Loss = 2.7110e-01, PNorm = 34.6513, GNorm = 1.9286, lr_0 = 1.8529e-04
Loss = 1.5518e-01, PNorm = 34.6523, GNorm = 2.3434, lr_0 = 1.8421e-04
Validation rmse = 0.892300
Validation r2 = 0.462778
Validation mae = 0.639012
Epoch 21
Loss = 2.4386e-01, PNorm = 34.6620, GNorm = 2.8458, lr_0 = 1.7370e-04
Validation rmse = 0.894794
Validation r2 = 0.459771
Validation mae = 0.631465
Epoch 22
Loss = 2.7807e-01, PNorm = 34.6695, GNorm = 1.2504, lr_0 = 1.6379e-04
Validation rmse = 0.897781
Validation r2 = 0.456159
Validation mae = 0.642876
Epoch 23
Loss = 1.3672e-01, PNorm = 34.6823, GNorm = 2.1821, lr_0 = 1.5354e-04
Loss = 2.8309e-01, PNorm = 34.6902, GNorm = 1.5855, lr_0 = 1.4478e-04
Validation rmse = 0.878871
Validation r2 = 0.478827
Validation mae = 0.617855
Epoch 24
Loss = 2.3992e-01, PNorm = 34.6973, GNorm = 1.9642, lr_0 = 1.3572e-04
Validation rmse = 0.895467
Validation r2 = 0.458958
Validation mae = 0.643262
Epoch 25
Loss = 2.9981e-01, PNorm = 34.7063, GNorm = 2.4084, lr_0 = 1.2798e-04
Loss = 2.7325e-01, PNorm = 34.7132, GNorm = 0.4742, lr_0 = 1.2068e-04
Validation rmse = 0.868760
Validation r2 = 0.490749
Validation mae = 0.615401
Epoch 26
Loss = 2.4206e-01, PNorm = 34.7214, GNorm = 0.5542, lr_0 = 1.1313e-04
Validation rmse = 0.853287
Validation r2 = 0.508728
Validation mae = 0.604524
Epoch 27
Loss = 2.2484e-01, PNorm = 34.7281, GNorm = 0.7578, lr_0 = 1.0605e-04
Loss = 2.5481e-01, PNorm = 34.7346, GNorm = 1.6023, lr_0 = 1.0000e-04
Loss = 3.7065e-01, PNorm = 34.7353, GNorm = 3.2891, lr_0 = 1.0000e-04
Validation rmse = 0.850229
Validation r2 = 0.512243
Validation mae = 0.608407
Epoch 28
Loss = 2.3689e-01, PNorm = 34.7419, GNorm = 1.4587, lr_0 = 1.0000e-04
Validation rmse = 0.852641
Validation r2 = 0.509471
Validation mae = 0.606977
Epoch 29
Loss = 2.2637e-01, PNorm = 34.7486, GNorm = 0.5422, lr_0 = 1.0000e-04
Validation rmse = 0.903930
Validation r2 = 0.448683
Validation mae = 0.648017
Model 0 best validation rmse = 0.846788 on epoch 17
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.970348
Model 0 test r2 = 0.542975
Model 0 test mae = 0.704085
Ensemble test rmse = 0.970348
Ensemble test r2 = 0.542975
Ensemble test mae = 0.704085
Fold 3
Splitting data with seed 3
Total scaffolds = 368 | train scaffolds = 298 | val scaffolds = 42 | test scaffolds = 28
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 37 | target average = 2.386357


Scaffold 1
Task 0: count = 37 | target average = 2.967741


Scaffold 2
Task 0: count = 29 | target average = 0.301030


Scaffold 3
Task 0: count = 22 | target average = 0.415222


Scaffold 4
Task 0: count = 22 | target average = 0.301030


Scaffold 5
Task 0: count = 19 | target average = 2.857016


Scaffold 6
Task 0: count = 16 | target average = 3.646747


Scaffold 7
Task 0: count = 15 | target average = 2.272125


Scaffold 8
Task 0: count = 15 | target average = 3.662865


Scaffold 9
Task 0: count = 15 | target average = 3.556767


Total size = 895 | train size = 716 | val size = 89 | test size = 90
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 8.4139e-01, PNorm = 34.0193, GNorm = 1.7236, lr_0 = 4.5357e-04
Validation rmse = 1.538904
Validation r2 = -0.092963
Validation mae = 1.245318
Epoch 1
Loss = 5.8670e-01, PNorm = 34.0433, GNorm = 2.1022, lr_0 = 8.0714e-04
Validation rmse = 1.308801
Validation r2 = 0.209450
Validation mae = 1.039664
Epoch 2
Loss = 5.4200e-01, PNorm = 34.0725, GNorm = 7.2352, lr_0 = 9.7106e-04
Loss = 4.9057e-01, PNorm = 34.1019, GNorm = 0.8621, lr_0 = 9.1566e-04
Validation rmse = 1.280165
Validation r2 = 0.243665
Validation mae = 1.041239
Epoch 3
Loss = 4.3262e-01, PNorm = 34.1311, GNorm = 1.6838, lr_0 = 8.5837e-04
Validation rmse = 1.056858
Validation r2 = 0.484515
Validation mae = 0.847785
Epoch 4
Loss = 4.4647e-01, PNorm = 34.1609, GNorm = 2.8076, lr_0 = 8.0940e-04
Loss = 4.3045e-01, PNorm = 34.1937, GNorm = 6.9611, lr_0 = 7.6323e-04
Validation rmse = 1.143600
Validation r2 = 0.396426
Validation mae = 0.924867
Epoch 5
Loss = 4.9368e-01, PNorm = 34.2213, GNorm = 4.3449, lr_0 = 7.1547e-04
Validation rmse = 1.031736
Validation r2 = 0.508731
Validation mae = 0.811221
Epoch 6
Loss = 4.8757e-01, PNorm = 34.2622, GNorm = 1.4296, lr_0 = 6.7070e-04
Loss = 3.5663e-01, PNorm = 34.2944, GNorm = 3.8672, lr_0 = 6.3244e-04
Validation rmse = 0.813799
Validation r2 = 0.694355
Validation mae = 0.626172
Epoch 7
Loss = 3.8731e-01, PNorm = 34.3168, GNorm = 1.7027, lr_0 = 5.9636e-04
Validation rmse = 0.891631
Validation r2 = 0.633096
Validation mae = 0.686527
Epoch 8
Loss = 3.3916e-01, PNorm = 34.3452, GNorm = 0.6487, lr_0 = 5.5905e-04
Validation rmse = 0.781593
Validation r2 = 0.718069
Validation mae = 0.558035
Epoch 9
Loss = 3.5486e-01, PNorm = 34.3705, GNorm = 1.3028, lr_0 = 5.2407e-04
Loss = 3.1003e-01, PNorm = 34.3908, GNorm = 0.6573, lr_0 = 4.9417e-04
Validation rmse = 0.839126
Validation r2 = 0.675035
Validation mae = 0.625265
Epoch 10
Loss = 3.5952e-01, PNorm = 34.4033, GNorm = 2.9285, lr_0 = 4.6598e-04
Validation rmse = 0.847949
Validation r2 = 0.668165
Validation mae = 0.633963
Epoch 11
Loss = 3.3778e-01, PNorm = 34.4205, GNorm = 2.3326, lr_0 = 4.3682e-04
Loss = 3.2897e-01, PNorm = 34.4364, GNorm = 1.5453, lr_0 = 4.1190e-04
Validation rmse = 0.759758
Validation r2 = 0.733601
Validation mae = 0.530776
Epoch 12
Loss = 3.1694e-01, PNorm = 34.4529, GNorm = 3.1959, lr_0 = 3.8613e-04
Validation rmse = 0.790206
Validation r2 = 0.711820
Validation mae = 0.579186
Epoch 13
Loss = 2.9498e-01, PNorm = 34.4663, GNorm = 3.1250, lr_0 = 3.6410e-04
Loss = 3.3437e-01, PNorm = 34.4788, GNorm = 1.5521, lr_0 = 3.4333e-04
Loss = 1.8497e-01, PNorm = 34.4800, GNorm = 1.3732, lr_0 = 3.4132e-04
Validation rmse = 0.826929
Validation r2 = 0.684413
Validation mae = 0.614417
Epoch 14
Loss = 3.4796e-01, PNorm = 34.4929, GNorm = 2.1023, lr_0 = 3.2185e-04
Validation rmse = 0.700064
Validation r2 = 0.773818
Validation mae = 0.491100
Epoch 15
Loss = 3.2099e-01, PNorm = 34.5088, GNorm = 0.4988, lr_0 = 3.0171e-04
Validation rmse = 0.730476
Validation r2 = 0.753740
Validation mae = 0.525796
Epoch 16
Loss = 1.4897e-01, PNorm = 34.5199, GNorm = 1.1401, lr_0 = 2.8450e-04
Loss = 3.0228e-01, PNorm = 34.5331, GNorm = 2.3105, lr_0 = 2.6827e-04
Validation rmse = 0.771968
Validation r2 = 0.724970
Validation mae = 0.559353
Epoch 17
Loss = 3.2475e-01, PNorm = 34.5464, GNorm = 1.2479, lr_0 = 2.5148e-04
Validation rmse = 0.726570
Validation r2 = 0.756366
Validation mae = 0.510264
Epoch 18
Loss = 2.7544e-01, PNorm = 34.5608, GNorm = 4.1313, lr_0 = 2.3575e-04
Loss = 3.3445e-01, PNorm = 34.5703, GNorm = 0.7711, lr_0 = 2.2230e-04
Validation rmse = 0.737230
Validation r2 = 0.749165
Validation mae = 0.532476
Epoch 19
Loss = 2.9085e-01, PNorm = 34.5812, GNorm = 0.5497, lr_0 = 2.0962e-04
Validation rmse = 0.694393
Validation r2 = 0.777467
Validation mae = 0.496990
Epoch 20
Loss = 3.1423e-01, PNorm = 34.5921, GNorm = 1.3363, lr_0 = 1.9650e-04
Loss = 3.1832e-01, PNorm = 34.6032, GNorm = 1.1585, lr_0 = 1.8529e-04
Loss = 3.2298e-01, PNorm = 34.6040, GNorm = 4.5053, lr_0 = 1.8421e-04
Validation rmse = 0.709552
Validation r2 = 0.767646
Validation mae = 0.503407
Epoch 21
Loss = 2.9000e-01, PNorm = 34.6136, GNorm = 1.4204, lr_0 = 1.7370e-04
Validation rmse = 0.778479
Validation r2 = 0.720310
Validation mae = 0.557350
Epoch 22
Loss = 3.1921e-01, PNorm = 34.6207, GNorm = 0.8696, lr_0 = 1.6379e-04
Validation rmse = 0.717631
Validation r2 = 0.762324
Validation mae = 0.514105
Epoch 23
Loss = 3.3596e-01, PNorm = 34.6301, GNorm = 2.1476, lr_0 = 1.5354e-04
Loss = 2.7412e-01, PNorm = 34.6391, GNorm = 0.8900, lr_0 = 1.4478e-04
Validation rmse = 0.751134
Validation r2 = 0.739614
Validation mae = 0.533345
Epoch 24
Loss = 2.9931e-01, PNorm = 34.6463, GNorm = 3.9024, lr_0 = 1.3572e-04
Validation rmse = 0.718891
Validation r2 = 0.761489
Validation mae = 0.514881
Epoch 25
Loss = 1.9578e-01, PNorm = 34.6537, GNorm = 1.1994, lr_0 = 1.2798e-04
Loss = 3.0282e-01, PNorm = 34.6608, GNorm = 1.3249, lr_0 = 1.2068e-04
Validation rmse = 0.694490
Validation r2 = 0.777405
Validation mae = 0.489776
Epoch 26
Loss = 3.2703e-01, PNorm = 34.6673, GNorm = 0.9687, lr_0 = 1.1313e-04
Validation rmse = 0.741526
Validation r2 = 0.746233
Validation mae = 0.529222
Epoch 27
Loss = 2.7867e-01, PNorm = 34.6749, GNorm = 1.4969, lr_0 = 1.0605e-04
Loss = 2.9682e-01, PNorm = 34.6804, GNorm = 2.0647, lr_0 = 1.0000e-04
Loss = 1.3962e-01, PNorm = 34.6808, GNorm = 2.8115, lr_0 = 1.0000e-04
Validation rmse = 0.756326
Validation r2 = 0.736002
Validation mae = 0.541793
Epoch 28
Loss = 3.0044e-01, PNorm = 34.6857, GNorm = 1.3426, lr_0 = 1.0000e-04
Validation rmse = 0.725235
Validation r2 = 0.757261
Validation mae = 0.521128
Epoch 29
Loss = 3.2273e-01, PNorm = 34.6915, GNorm = 1.7155, lr_0 = 1.0000e-04
Validation rmse = 0.680476
Validation r2 = 0.786299
Validation mae = 0.481559
Model 0 best validation rmse = 0.680476 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.678777
Model 0 test r2 = 0.777122
Model 0 test mae = 0.441319
Ensemble test rmse = 0.678777
Ensemble test r2 = 0.777122
Ensemble test mae = 0.441319
Fold 4
Splitting data with seed 4
Total scaffolds = 368 | train scaffolds = 281 | val scaffolds = 48 | test scaffolds = 39
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 37 | target average = 2.386357


Scaffold 1
Task 0: count = 37 | target average = 2.967741


Scaffold 2
Task 0: count = 29 | target average = 0.301030


Scaffold 3
Task 0: count = 22 | target average = 0.415222


Scaffold 4
Task 0: count = 22 | target average = 0.301030


Scaffold 5
Task 0: count = 19 | target average = 2.857016


Scaffold 6
Task 0: count = 16 | target average = 3.646747


Scaffold 7
Task 0: count = 15 | target average = 2.272125


Scaffold 8
Task 0: count = 15 | target average = 3.556767


Scaffold 9
Task 0: count = 15 | target average = 3.662865


Total size = 895 | train size = 716 | val size = 89 | test size = 90
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 8.7138e-01, PNorm = 34.0170, GNorm = 2.5640, lr_0 = 4.5357e-04
Validation rmse = 1.118537
Validation r2 = 0.372127
Validation mae = 0.896039
Epoch 1
Loss = 8.7293e-01, PNorm = 34.0407, GNorm = 16.5457, lr_0 = 8.0714e-04
Validation rmse = 1.255939
Validation r2 = 0.208395
Validation mae = 1.097035
Epoch 2
Loss = 4.7791e-01, PNorm = 34.0706, GNorm = 1.1943, lr_0 = 9.7106e-04
Loss = 5.5411e-01, PNorm = 34.1081, GNorm = 2.3355, lr_0 = 9.1566e-04
Validation rmse = 1.041142
Validation r2 = 0.456009
Validation mae = 0.802376
Epoch 3
Loss = 4.8413e-01, PNorm = 34.1489, GNorm = 5.3092, lr_0 = 8.5837e-04
Validation rmse = 1.072404
Validation r2 = 0.422850
Validation mae = 0.864604
Epoch 4
Loss = 3.7749e-01, PNorm = 34.1839, GNorm = 1.3908, lr_0 = 8.0940e-04
Loss = 3.7636e-01, PNorm = 34.2191, GNorm = 0.9499, lr_0 = 7.6323e-04
Validation rmse = 0.942123
Validation r2 = 0.554562
Validation mae = 0.710484
Epoch 5
Loss = 3.5617e-01, PNorm = 34.2596, GNorm = 3.9948, lr_0 = 7.1547e-04
Validation rmse = 0.964382
Validation r2 = 0.533266
Validation mae = 0.715042
Epoch 6
Loss = 3.2079e-01, PNorm = 34.2865, GNorm = 0.9842, lr_0 = 6.7070e-04
Loss = 3.2216e-01, PNorm = 34.3104, GNorm = 5.1665, lr_0 = 6.3244e-04
Validation rmse = 1.051259
Validation r2 = 0.445386
Validation mae = 0.828464
Epoch 7
Loss = 3.2297e-01, PNorm = 34.3286, GNorm = 6.5998, lr_0 = 5.9636e-04
Validation rmse = 0.929674
Validation r2 = 0.566256
Validation mae = 0.689856
Epoch 8
Loss = 3.2384e-01, PNorm = 34.3461, GNorm = 1.2476, lr_0 = 5.5905e-04
Validation rmse = 1.000813
Validation r2 = 0.497336
Validation mae = 0.772511
Epoch 9
Loss = 3.8397e-01, PNorm = 34.3677, GNorm = 1.2654, lr_0 = 5.2407e-04
Loss = 2.9252e-01, PNorm = 34.3858, GNorm = 2.9407, lr_0 = 4.9417e-04
Validation rmse = 0.966723
Validation r2 = 0.530996
Validation mae = 0.702463
Epoch 10
Loss = 3.0148e-01, PNorm = 34.3987, GNorm = 4.4544, lr_0 = 4.6598e-04
Validation rmse = 0.916882
Validation r2 = 0.578110
Validation mae = 0.666507
Epoch 11
Loss = 2.7605e-01, PNorm = 34.4130, GNorm = 1.7385, lr_0 = 4.3682e-04
Loss = 2.9874e-01, PNorm = 34.4250, GNorm = 2.4124, lr_0 = 4.1190e-04
Validation rmse = 0.983935
Validation r2 = 0.514147
Validation mae = 0.738193
Epoch 12
Loss = 2.7422e-01, PNorm = 34.4391, GNorm = 1.4372, lr_0 = 3.8613e-04
Validation rmse = 0.915977
Validation r2 = 0.578943
Validation mae = 0.673297
Epoch 13
Loss = 3.0602e-01, PNorm = 34.4520, GNorm = 2.5995, lr_0 = 3.6410e-04
Loss = 2.8046e-01, PNorm = 34.4626, GNorm = 0.8844, lr_0 = 3.4333e-04
Loss = 1.6366e-01, PNorm = 34.4638, GNorm = 1.0833, lr_0 = 3.4132e-04
Validation rmse = 0.944780
Validation r2 = 0.552046
Validation mae = 0.681623
Epoch 14
Loss = 2.6309e-01, PNorm = 34.4757, GNorm = 0.7428, lr_0 = 3.2185e-04
Validation rmse = 0.937959
Validation r2 = 0.558491
Validation mae = 0.692283
Epoch 15
Loss = 2.5606e-01, PNorm = 34.4875, GNorm = 2.9240, lr_0 = 3.0171e-04
Validation rmse = 0.921763
Validation r2 = 0.573607
Validation mae = 0.682183
Epoch 16
Loss = 3.5098e-01, PNorm = 34.4979, GNorm = 1.2117, lr_0 = 2.8450e-04
Loss = 2.7236e-01, PNorm = 34.5073, GNorm = 0.6402, lr_0 = 2.6827e-04
Validation rmse = 0.920829
Validation r2 = 0.574471
Validation mae = 0.659342
Epoch 17
Loss = 2.6528e-01, PNorm = 34.5195, GNorm = 0.5975, lr_0 = 2.5148e-04
Validation rmse = 0.925821
Validation r2 = 0.569844
Validation mae = 0.689015
Epoch 18
Loss = 2.7931e-01, PNorm = 34.5312, GNorm = 0.6378, lr_0 = 2.3575e-04
Loss = 2.5182e-01, PNorm = 34.5417, GNorm = 1.7461, lr_0 = 2.2230e-04
Validation rmse = 0.909795
Validation r2 = 0.584607
Validation mae = 0.655001
Epoch 19
Loss = 2.5383e-01, PNorm = 34.5495, GNorm = 0.6401, lr_0 = 2.0962e-04
Validation rmse = 0.911903
Validation r2 = 0.582680
Validation mae = 0.689288
Epoch 20
Loss = 2.5477e-01, PNorm = 34.5590, GNorm = 1.9385, lr_0 = 1.9650e-04
Loss = 2.7287e-01, PNorm = 34.5677, GNorm = 0.6310, lr_0 = 1.8529e-04
Loss = 2.8522e-01, PNorm = 34.5686, GNorm = 1.5868, lr_0 = 1.8421e-04
Validation rmse = 0.930327
Validation r2 = 0.565647
Validation mae = 0.687682
Epoch 21
Loss = 2.4668e-01, PNorm = 34.5772, GNorm = 0.7336, lr_0 = 1.7370e-04
Validation rmse = 0.909914
Validation r2 = 0.584498
Validation mae = 0.673301
Epoch 22
Loss = 2.5497e-01, PNorm = 34.5844, GNorm = 2.1152, lr_0 = 1.6379e-04
Validation rmse = 0.912249
Validation r2 = 0.582364
Validation mae = 0.664818
Epoch 23
Loss = 1.8105e-01, PNorm = 34.5918, GNorm = 2.2010, lr_0 = 1.5354e-04
Loss = 2.5009e-01, PNorm = 34.5984, GNorm = 1.5638, lr_0 = 1.4478e-04
Validation rmse = 0.908933
Validation r2 = 0.585394
Validation mae = 0.664665
Epoch 24
Loss = 2.7137e-01, PNorm = 34.6058, GNorm = 2.4731, lr_0 = 1.3572e-04
Validation rmse = 0.940006
Validation r2 = 0.556562
Validation mae = 0.683808
Epoch 25
Loss = 2.0527e-01, PNorm = 34.6121, GNorm = 3.0240, lr_0 = 1.2798e-04
Loss = 2.6682e-01, PNorm = 34.6178, GNorm = 0.4683, lr_0 = 1.2068e-04
Validation rmse = 0.929344
Validation r2 = 0.566564
Validation mae = 0.678608
Epoch 26
Loss = 2.4230e-01, PNorm = 34.6239, GNorm = 0.7665, lr_0 = 1.1313e-04
Validation rmse = 0.911085
Validation r2 = 0.583428
Validation mae = 0.668896
Epoch 27
Loss = 2.3787e-01, PNorm = 34.6296, GNorm = 1.5552, lr_0 = 1.0605e-04
Loss = 2.4748e-01, PNorm = 34.6345, GNorm = 1.0618, lr_0 = 1.0000e-04
Loss = 3.5679e-01, PNorm = 34.6349, GNorm = 2.6164, lr_0 = 1.0000e-04
Validation rmse = 0.959114
Validation r2 = 0.538351
Validation mae = 0.700415
Epoch 28
Loss = 2.4940e-01, PNorm = 34.6401, GNorm = 1.2120, lr_0 = 1.0000e-04
Validation rmse = 0.936163
Validation r2 = 0.560180
Validation mae = 0.683264
Epoch 29
Loss = 2.4871e-01, PNorm = 34.6445, GNorm = 3.0917, lr_0 = 1.0000e-04
Validation rmse = 0.943955
Validation r2 = 0.552828
Validation mae = 0.686908
Model 0 best validation rmse = 0.908933 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test rmse = 0.946792
Model 0 test r2 = 0.438276
Model 0 test mae = 0.579953
Ensemble test rmse = 0.946792
Ensemble test r2 = 0.438276
Ensemble test mae = 0.579953
5-fold cross validation
	Seed 0 ==> test rmse = 0.824925
	Seed 0 ==> test r2 = 0.660210
	Seed 0 ==> test mae = 0.599342
	Seed 1 ==> test rmse = 0.724905
	Seed 1 ==> test r2 = 0.735845
	Seed 1 ==> test mae = 0.552496
	Seed 2 ==> test rmse = 0.970348
	Seed 2 ==> test r2 = 0.542975
	Seed 2 ==> test mae = 0.704085
	Seed 3 ==> test rmse = 0.678777
	Seed 3 ==> test r2 = 0.777122
	Seed 3 ==> test mae = 0.441319
	Seed 4 ==> test rmse = 0.946792
	Seed 4 ==> test r2 = 0.438276
	Seed 4 ==> test mae = 0.579953
Overall test rmse = 0.829150 +/- 0.115994
Overall test r2 = 0.630886 +/- 0.124971
Overall test mae = 0.575439 +/- 0.084447
Elapsed time = 0:06:34
